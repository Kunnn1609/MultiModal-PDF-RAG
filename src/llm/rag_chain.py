import dashscope
import os
from dotenv import load_dotenv
import pickle
from langchain_community.vectorstores import Chroma
from langchain_community.retrievers import BM25Retriever

# --- å°è¯•å¯¼å…¥ Rerank æ¨¡å— ---
# è¿™æ˜¯ä¸€ä¸ªå®¹é”™è®¾è®¡ï¼šå¦‚æœ src.rag.reranker æ²¡å†™å¥½ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨å›é€€åˆ°ä¸é‡æ’åºæ¨¡å¼ï¼Œé˜²æ­¢æŠ¥é”™
try:
    from src.rag.reranker import get_reranker
    
    def rerank_documents(query, docs, top_k=3):
        """
        ä½¿ç”¨ BGE-Reranker å¯¹æ–‡æ¡£è¿›è¡Œç²¾ç»†åŒ–æ’åº
        """
        if not docs:
            return []
        
        # è·å–å•ä¾‹æ¨¡å‹
        reranker = get_reranker()
        
        # æ„é€ æ¨¡å‹éœ€è¦çš„è¾“å…¥å¯¹: [[Query, Doc1], [Query, Doc2]...]
        pairs = [[query, d.page_content] for d in docs]
        
        # è®¡ç®—å¾—åˆ†
        scores = reranker.compute_score(pairs)
        
        # å…¼å®¹æ€§å¤„ç†ï¼šå¦‚æœåªæœ‰ä¸€ä¸ªæ–‡æ¡£ï¼Œscores å¯èƒ½æ˜¯ä¸€ä¸ª float
        if isinstance(scores, float):
            scores = [scores]
            
        # æ‰“åŒ… (Doc, Score) å¹¶æŒ‰åˆ†æ•°é™åºæ’åˆ—
        doc_score_pairs = list(zip(docs, scores))
        doc_score_pairs.sort(key=lambda x: x[1], reverse=True)
        
        # è¿”å›å‰ Top-K ä¸ªæ–‡æ¡£
        return [doc for doc, score in doc_score_pairs[:top_k]]

except ImportError:
    print("âš ï¸ æœªæ‰¾åˆ° Rerank æ¨¡å— (src.rag.reranker)ï¼Œå°†è·³è¿‡é‡æ’åºæ­¥éª¤ã€‚")
    def rerank_documents(query, docs, top_k=3):
        return docs[:top_k]


# é…ç½® API KEY
# åŠ è½½ .env æ–‡ä»¶é‡Œçš„ç¯å¢ƒå˜é‡
load_dotenv()
# è¯·ç”¨æˆ·è‡ªå·±å¡«å…¥ Key
api_key = os.getenv("DASHSCOPE_API_KEY")
if api_key is None:
    raise ValueError("âš ï¸ æœªæ‰¾åˆ° DASHSCOPE_API_KEYï¼Œè¯·æ£€æŸ¥ .env æ–‡ä»¶ï¼")

dashscope.api_key = api_key
def rewrite_query(user_query, chat_history):
    """
    é€šç”¨ç‰ˆå¤šè½®å¯¹è¯æ”¹å†™ï¼šå°†ç”¨æˆ·çš„å£è¯­åŒ–æé—®æ”¹å†™ä¸ºé€‚åˆæ£€ç´¢çš„å®Œæ•´å¥å­
    """
    if not chat_history or len(chat_history) < 1:
        return user_query

    # åªçœ‹æœ€è¿‘ 2 è½®å¯¹è¯ï¼Œé¿å…ä¸Šä¸‹æ–‡è¿‡é•¿å¹²æ‰°
    recent_history = chat_history[-2:]
    history_text = ""
    for msg in recent_history:
        role = "ç”¨æˆ·" if msg['role'] == 'user' else "åŠ©æ‰‹"
        history_text += f"{role}: {msg['content']}\n"

    # ã€é€šç”¨åŒ–æç¤ºè¯ã€‘
    prompt = f"""ä»»åŠ¡ï¼šæ ¹æ®å¯¹è¯å†å²ï¼Œå°†ç”¨æˆ·çš„æœ€æ–°æé—®æ”¹å†™ä¸ºä¸€ä¸ªæŒ‡ä»£æ¸…æ™°ã€ç‹¬ç«‹å®Œæ•´çš„æœç´¢è¯­å¥ã€‚
    
    è¦æ±‚ï¼š
    1. è¡¥å…¨æŒ‡ä»£è¯ï¼ˆå¦‚â€œå®ƒâ€ã€â€œè¿™ä¸ªâ€ã€â€œå…¶â€ï¼‰ï¼Œä½¿å…¶æŒ‡ä»£ä¸Šæ–‡ä¸­çš„å…·ä½“å¯¹è±¡ã€‚
    2. ä¿æŒåŸæ„ï¼Œä¸è¦å›ç­”é—®é¢˜ï¼Œåªéœ€è¾“å‡ºæ”¹å†™åçš„å¥å­ã€‚
    
    å¯¹è¯å†å²ï¼š
    {history_text}
    
    ç”¨æˆ·æœ€æ–°æé—®ï¼š{user_query}
    
    æ”¹å†™ç»“æœï¼š"""

    try:
        response = dashscope.Generation.call(
            model='qwen-turbo',
            messages=[{'role': 'user', 'content': prompt}],
            result_format='message'
        )
        if response.status_code == 200:
            rewritten = response.output.choices[0].message.content.strip()
            # print(f"ğŸ” [Query Rewrite] {user_query} -> {rewritten}")
            return rewritten
    except Exception as e:
        print(f"âš ï¸ æ”¹å†™å¤±è´¥ï¼Œä½¿ç”¨åŸé—®é¢˜: {e}")
        
    return user_query

def get_answer_stream(query, db_path, chat_history=[], embedding_model=None):
    """
    æ ¸å¿ƒé—®ç­”é“¾è·¯ï¼š
    1. æ”¹å†™ -> 2. æ··åˆæ£€ç´¢(Vector+BM25) -> 3. é‡æ’åº(Rerank) -> 4. ä¸Šä¸‹æ–‡æ„å»º -> 5. æµå¼ç”Ÿæˆ
    
    Args:
        embedding_model: å¿…é¡»ä¼ å…¥å·²åŠ è½½çš„ HuggingFaceEmbeddings å¯¹è±¡
    """
    # 0. æ£€æŸ¥æ¨¡å‹å‚æ•°
    if embedding_model is None:
        raise ValueError("âŒ get_answer_stream è°ƒç”¨é”™è¯¯ï¼šå¿…é¡»ä¼ å…¥ embedding_model å‚æ•°ï¼")

    # 1. æŸ¥è¯¢æ”¹å†™
    search_query = rewrite_query(query, chat_history)
    print(f"ğŸ” [æ­£åœ¨æ£€ç´¢] {search_query}")

    if not os.path.exists(db_path):
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°æ•°æ®åº“è·¯å¾„: {db_path}")

    # --- 2. æ··åˆæ£€ç´¢ (Hybrid Search) ---
    
    # 2.1 å‘é‡æ£€ç´¢ (Vector Search)
    vector_docs = []
    try:
        # ç›´æ¥ä½¿ç”¨ä¼ å…¥çš„ embedding_modelï¼Œæ— éœ€é‡æ–°åŠ è½½ï¼Œé€Ÿåº¦æå¿«
        vectordb = Chroma(persist_directory=db_path, embedding_function=embedding_model)
        # å¬å› Top-10 ç»™ Rerank ç­›é€‰
        vector_docs = vectordb.similarity_search(search_query, k=10)
    except Exception as e:
        print(f"âš ï¸ å‘é‡æ£€ç´¢å¼‚å¸¸: {e}")
    
    # 2.2 å…³é”®è¯æ£€ç´¢ (BM25)
    bm25_docs = []
    bm25_path = os.path.join(db_path, "bm25_data.pkl")
    if os.path.exists(bm25_path):
        try:
            with open(bm25_path, "rb") as f:
                data = pickle.load(f)
                # å®æ—¶æ„å»ºæ£€ç´¢å™¨ (å†…å­˜æ“ä½œï¼Œå¾ˆå¿«)
                bm25_retriever = BM25Retriever.from_texts(
                    texts=data["documents"], 
                    metadatas=data["metadatas"]
                )
                bm25_retriever.k = 10
                bm25_docs = bm25_retriever.get_relevant_documents(search_query)
        except Exception as e:
            print(f"âš ï¸ BM25 è¯»å–å¤±è´¥: {e}")

    # 2.3 ç»“æœèåˆä¸å»é‡
    combined_docs = vector_docs + bm25_docs
    unique_docs = []
    seen_content = set()
    
    for doc in combined_docs:
        # ç®€å•å»é‡ï¼šå†…å®¹å®Œå…¨ä¸€è‡´åˆ™è·³è¿‡
        if doc.page_content not in seen_content:
            unique_docs.append(doc)
            seen_content.add(doc.page_content)

    # --- 3. é‡æ’åº (Rerank) ---
    # ä»èåˆç»“æœä¸­é€‰å‡ºæœ€ç›¸å…³çš„ Top-3
    final_docs = rerank_documents(search_query, unique_docs, top_k=3)
    
    # --- 4. æ„å»ºä¸Šä¸‹æ–‡ (Context) ---
    context_list = []
    for doc in final_docs:
        # å°è¯•è·å–é¡µç ï¼Œå¦‚æœæ²¡æœ‰åˆ™æ˜¾ç¤º ?
        page = doc.metadata.get('source_page', '?')
        context_list.append(f"[å‚è€ƒæ¥æº - ç¬¬{page}é¡µ]\n{doc.page_content}")
    
    context_str = "\n\n".join(context_list)

    # --- 5. æ„å»ºé€šç”¨ç‰ˆç³»ç»Ÿæç¤ºè¯ (System Prompt) ---
    system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡æ¡£æ™ºèƒ½åˆ†æåŠ©æ‰‹ã€‚è¯·ä¸¥æ ¼æ ¹æ®ç”¨æˆ·ä¸Šä¼ çš„ã€å‚è€ƒèµ„æ–™ã€‘æ¥å›ç­”é—®é¢˜ã€‚

ã€å›ç­”æ ¸å¿ƒåŸåˆ™ã€‘
1. **ä¾æ®åŸæ–‡**ï¼šæ‰€æœ‰ç­”æ¡ˆå¿…é¡»ä»ä¸Šä¸‹æ–‡ä¸­æå–ï¼Œä¸¥ç¦ä½¿ç”¨ä½ è‡ªå¸¦çš„å¤–éƒ¨çŸ¥è¯†è¿›è¡Œç¼–é€ ã€‚
2. **å®¢è§‚ä¸­ç«‹**ï¼šå¦‚æœå‚è€ƒèµ„æ–™ä¸­æ²¡æœ‰æåˆ°ç›¸å…³å†…å®¹ï¼Œè¯·ç›´æ¥å›ç­”ï¼šâ€œæŠ±æ­‰ï¼Œå½“å‰æ–‡æ¡£ä¸­æœªæ‰¾åˆ°å…³äºæ­¤é—®é¢˜çš„æè¿°ã€‚â€
3. **æ¥æºæ ‡æ³¨**ï¼šåœ¨å›ç­”çš„å…³é”®ä¿¡æ¯åï¼Œè¯·å°½é‡ç”¨æ‹¬å·æ ‡æ³¨æ¥æºé¡µç ï¼Œä¾‹å¦‚ (P5)ã€‚

ã€æ’ç‰ˆè¦æ±‚ã€‘
1. **ç»“æ„åŒ–**ï¼šè¯·ä¼˜å…ˆä½¿ç”¨ Markdown åˆ—è¡¨ (Bullet Points) æ¥ç»„ç»‡ç­”æ¡ˆï¼Œä½¿å…¶æ¸…æ™°æ˜“è¯»ã€‚
2. **é‡ç‚¹é«˜äº®**ï¼šå¯¹å…³é”®çš„æ•°æ®ã€ç»“è®ºã€å®ä½“åç§°ï¼Œè¯·ä½¿ç”¨ **åŠ ç²—** æ ‡è®°ã€‚

ã€å‚è€ƒèµ„æ–™ã€‘
{context_str}
"""

    # --- 6. è°ƒç”¨å¤§æ¨¡å‹ (Qwen) ---
    messages = [
        {'role': 'system', 'content': system_prompt},
        {'role': 'user', 'content': query} # è¿™é‡Œä½¿ç”¨åŸå§‹ query ä¿æŒç”¨æˆ·è¯­æ°”ï¼Œcontext å·²ç»åŒ…å«äº†å‡†ç¡®ä¿¡æ¯
    ]

    responses = dashscope.Generation.call(
        model='qwen-turbo',
        messages=messages,
        result_format='message',
        stream=True,
        incremental_output=True
    )
    
    # è¿”å›ï¼š(å“åº”æµ, ç²¾é€‰å‡ºçš„æ–‡æ¡£åˆ—è¡¨)
    return responses, final_docs