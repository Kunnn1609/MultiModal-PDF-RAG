import re
import fitz  # PyMuPDF
import numpy as np
import cv2
import logging
from paddleocr import PaddleOCR

# å±è”½ PaddleOCR çš„è°ƒè¯•æ—¥å¿—ï¼Œä¿æŒæ§åˆ¶å°æ•´æ´
logging.getLogger("ppocr").setLevel(logging.WARNING)

def is_text_garbled_or_empty(text, min_length=15):
    """
    å¯å‘å¼è§„åˆ™ï¼šæ›´æ™ºèƒ½åœ°åˆ¤æ–­æå–çš„æ–‡æœ¬æ˜¯å¦ä¸ºä¹±ç æˆ–å†…å®¹è¿‡å°‘
    """
    clean_text = text.replace(" ", "").replace("\n", "").strip()
    
    # 1. å¦‚æœå®Œå…¨æ²¡æœ‰å†…å®¹ï¼Œå¿…é¡» OCR
    if not clean_text:
        return True

    # 2. æ£€æŸ¥ CID ä¹±ç  (è¿™æ˜¯ PDF å­—ä½“ç¼ºå¤±æœ€æ˜¾è‘—çš„ç‰¹å¾)
    # ä¾‹å¦‚ï¼š(cid:1234) è¿™ç§æ ¼å¼
    if len(re.findall(r'\(cid:\d+\)', text)) > 5:
        # print(f"   [æ£€æµ‹] å‘ç°å¤§é‡ (cid) ç¼–ç ï¼Œåˆ¤å®šä¸ºä¹±ç ã€‚")
        return True

    # 3. æ£€æŸ¥ä¸­æ–‡å æ¯”
    # å­¦æœ¯è®ºæ–‡é€šå¸¸å«æœ‰å¤§é‡æ±‰å­—ã€‚å¦‚æœæå–ç»“æœæœ‰æ±‰å­—ï¼Œè¯´æ˜æå–é“¾è·¯åŸºæœ¬æ­£å¸¸
    has_chinese = any('\u4e00' <= char <= '\u9fff' for char in clean_text)
    
    # å¦‚æœå­—æ•°å¾ˆå°‘ä¸”æ²¡æœ‰ä¸­æ–‡ï¼ˆæ’é™¤æ‰é¡µç æˆ–Logoç­‰å°å—æå–ç‰©ï¼‰
    if len(clean_text) < min_length and not has_chinese:
        return True
    
    # 4. æ£€æŸ¥éæ³•å­—ç¬¦æ¯”ä¾‹ (å¦‚ â–¯, ?)
    bad_chars = len(re.findall(r'[â–¯\?]', clean_text))
    if len(clean_text) > 0 and (bad_chars / len(clean_text)) > 0.3:
        return True

    return False

def clean_header_footer(text):
    """
    ã€æ–°å¢åŠŸèƒ½ã€‘æ¸…æ´—é¡µçœ‰ã€é¡µè„šå’Œå‡ºç‰ˆå…ƒæ•°æ®å™ªéŸ³
    ä¿ç•™æ‘˜è¦ï¼ˆAbstractï¼‰ï¼Œä½†è¿‡æ»¤æ‰å¹²æ‰°é˜…è¯»çš„ç‰ˆé¢ä¿¡æ¯
    """
    lines = text.split('\n')
    cleaned_lines = []
    
    for line in lines:
        content = line.strip()
        if not content:
            continue
            
        # 1. è¿‡æ»¤çº¯æ•°å­— (é€šå¸¸æ˜¯é¡µç ï¼Œå¦‚ "1", "45")
        if content.isdigit() and len(content) < 5:
            continue
            
        # 2. è¿‡æ»¤å¸¸è§çš„é¡µçœ‰/å‡ºç‰ˆä¿¡æ¯ç‰¹å¾
        # è§„åˆ™ï¼šé•¿åº¦è¾ƒçŸ­(å°äº80å­—ç¬¦) ä¸” åŒ…å«ç‰¹å®šå…³é”®è¯
        # è¿™äº›è¯é€šå¸¸å‡ºç°åœ¨é¡µçœ‰é¡µè„šï¼Œè€Œä¸æ˜¯æ­£æ–‡ä¸­
        is_header_footer = False
        if len(content) < 100:
            noise_keywords = [
                "ISSN", "DOI", "http", "www.", "cnki", 
                "å­¦æŠ¥", "Journal", "Vol.", "No.", "æœŸ", "å·",
                "ç½‘ç»œé¦–å‘", "å¼•ç”¨æ ¼å¼", "Computer Science", "Page"
            ]
            if any(k in content for k in noise_keywords):
                is_header_footer = True
        
        if not is_header_footer:
            cleaned_lines.append(line)
            
    return "\n".join(cleaned_lines)

def ocr_page_image(page, ocr_engine):
    """
    å°†é¡µé¢è½¬ä¸ºå›¾ç‰‡å¹¶è¿›è¡Œ OCR
    """
    print("   [OCR] å¯åŠ¨è§†è§‰è¯†åˆ«ä¸­...")
    
    # æ¸²æŸ“é«˜åˆ†è¾¨ç‡å›¾ç‰‡ (zoom=2 ä¿è¯æ¸…æ™°åº¦)
    zoom = 2
    mat = fitz.Matrix(zoom, zoom)
    pix = page.get_pixmap(matrix=mat, alpha=False)
    
    # è½¬æ¢ä¸º OpenCV æ ¼å¼ä¾› PaddleOCR ä½¿ç”¨
    img_data = np.frombuffer(pix.tobytes("png"), dtype=np.uint8)
    img = cv2.imdecode(img_data, cv2.IMREAD_COLOR)

    # è°ƒç”¨ OCR
    result = ocr_engine.predict(img)
    
    ocr_text = ""
    if result:
        # å…¼å®¹ PaddleOCR ä¸åŒçš„è¿”å›æ ¼å¼ (list or dict)
        if isinstance(result, list):
            for line in result:
                if isinstance(line, (list, tuple)) and len(line) >= 2:
                    content = line[1]
                    if isinstance(content, (list, tuple)) and len(content) > 0:
                        ocr_text += str(content[0]) + "\n"
                    elif isinstance(content, str):
                        ocr_text += content + "\n"
        elif isinstance(result, dict) and 'rec_text' in result:
            ocr_text = result['rec_text']
            
    return ocr_text

def smart_extract(pdf_path, ocr_engine):
    """
    ä¸»è§£æé€»è¾‘ï¼š
    1. å°è¯•ç›´æ¥æå– -> å¤±è´¥åˆ™ OCR
    2. é¡µçœ‰é¡µè„šæ¸…æ´— (ä¿ç•™æ‘˜è¦)
    3. å‚è€ƒæ–‡çŒ®æˆªæ–­ (é˜²æ­¢è¯­ä¹‰æ±¡æŸ“)
    """
    doc = fitz.open(pdf_path)
    full_content = []
    total_pages = len(doc)
    
    # ğŸ›‘ å‚è€ƒæ–‡çŒ®æˆªæ–­æ ‡å¿—ä½
    stop_parsing = False 

    print(f"ğŸš€ å¼€å§‹æ™ºèƒ½è§£æ: {pdf_path} (å…± {total_pages} é¡µ)")

    for page_num, page in enumerate(doc):
        # 0. å¦‚æœå·²ç»è§¦å‘äº†æˆªæ–­æœºåˆ¶ï¼Œç›´æ¥è·³è¿‡å‰©ä½™é¡µé¢
        if stop_parsing:
            print(f"ğŸ›‘ [æˆªæ–­] è·³è¿‡ç¬¬ {page_num + 1} é¡µ (å‚è€ƒæ–‡çŒ®/é™„å½•åŒºåŸŸ)ã€‚")
            break

        # 1. å°è¯•ç›´æ¥è·å–æ–‡æœ¬
        raw_text = page.get_text().strip()
        
        # 2. åˆ¤æ–­æ˜¯å¦æ»¡è¶³ OCR è§¦å‘æ¡ä»¶
        need_ocr = False
        method = "Direct"
        
        if not raw_text:
            need_ocr = True
            reason = "æ— æ–‡æœ¬æµï¼ˆå¯èƒ½æ˜¯çº¯å›¾ç‰‡ï¼‰"
        elif is_text_garbled_or_empty(raw_text):
            need_ocr = True
            reason = "æ£€æµ‹åˆ°ä¹±ç æˆ–æ— æ•ˆçŸ­æ–‡æœ¬"
        
        # 3. æ‰§è¡Œæå–
        final_text = ""
        if need_ocr:
            print(f"ğŸ“„ ç¬¬ {page_num + 1} é¡µ: âš ï¸ {reason}ï¼Œæ‰§è¡Œ OCR...")
            final_text = ocr_page_image(page, ocr_engine)
            method = "OCR"
        else:
            # print(f"ğŸ“„ ç¬¬ {page_num + 1} é¡µ: âœ… æ–‡æœ¬æå–æˆåŠŸ")
            final_text = raw_text

        # 4. ã€æ–°å¢ã€‘æ¸…æ´—é¡µçœ‰é¡µè„š
        # åœ¨å¤„ç†å‚è€ƒæ–‡çŒ®ä¹‹å‰å…ˆæ¸…æ´—ï¼Œé˜²æ­¢é¡µçœ‰é‡Œçš„å…³é”®è¯å¹²æ‰°åˆ¤æ–­
        final_text = clean_header_footer(final_text)

        # 5. ã€æ–°å¢ã€‘æ£€æµ‹å‚è€ƒæ–‡çŒ®å¹¶æˆªæ–­
        # é€»è¾‘ï¼šåªåœ¨æ–‡æ¡£ååŠéƒ¨åˆ†æ£€æŸ¥ï¼Œé˜²æ­¢ç›®å½•ä¸­å‡ºç°â€œå‚è€ƒæ–‡çŒ®â€å¯¼è‡´è¯¯æ€
        if page_num > total_pages * 0.5:
            lines = final_text.split('\n')
            cleaned_lines_for_this_page = []
            
            for line in lines:
                # å»é™¤ç©ºæ ¼åæ£€æŸ¥å…³é”®è¯
                clean_line = line.strip().replace(" ", "")
                # æ£€æŸ¥å¸¸è§çš„ä¸­è‹±æ–‡å‚è€ƒæ–‡çŒ®æ ‡é¢˜ (ç‹¬å ä¸€è¡Œæˆ–æçŸ­)
                if clean_line in ["å‚è€ƒæ–‡çŒ®", "References", "Bibliography", "ä¸»è¦å‚è€ƒæ–‡çŒ®", "Reference"]:
                    stop_parsing = True
                    print(f"âœ‚ï¸ [æ£€æµ‹] åœ¨ç¬¬ {page_num + 1} é¡µå‘ç°å‚è€ƒæ–‡çŒ®åˆ—è¡¨ï¼Œå¯åŠ¨æˆªæ–­ã€‚")
                    break 
                cleaned_lines_for_this_page.append(line)
            
            # å¦‚æœæœ¬é¡µè§¦å‘äº†æˆªæ–­ï¼Œåªä¿ç•™æˆªæ–­å‰çš„å†…å®¹
            if stop_parsing:
                final_text = "\n".join(cleaned_lines_for_this_page)
                # å¦‚æœè¿™ä¸€é¡µæˆªæ–­åæ²¡å‰©ä»€ä¹ˆå†…å®¹äº†ï¼Œå°±ç›´æ¥è·³è¿‡ä¸å­˜
                if not final_text.strip():
                    continue

        # 6. å­˜å…¥ç»“æœ
        if final_text.strip():
            full_content.append({
                "page_number": page_num + 1,
                "content": final_text,
                "method": method
            })

    doc.close()
    return full_content

if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    print("â³ åˆå§‹åŒ– PaddleOCR å¼•æ“...")
    engine = PaddleOCR(lang="ch", use_angle_cls=True)

    # è¯·æ›¿æ¢ä¸ºä½ æœ¬åœ°çš„æµ‹è¯•æ–‡ä»¶è·¯å¾„
    test_pdf = r"D:\workspace\finale_workspace\PDF_RAG_Project\data\raw\test.pdf"
    
    # æ¨¡æ‹Ÿè¿è¡Œ
    # results = smart_extract(test_pdf, engine)
    # for res in results:
    #     print(f"--- Page {res['page_number']} ---")
    #     print(res['content'][:200] + "...")