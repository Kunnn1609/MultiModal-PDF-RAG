import sys
import os

# 1. ç¯å¢ƒä¸è·¯å¾„å¤„ç†
os.environ["PYTHONNOUSERSITE"] = "1"
sys.path = [p for p in sys.path if "AppData" not in p]
project_root = os.path.dirname(os.path.abspath(__file__))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

import streamlit as st
# å¿…é¡»å…ˆå®‰è£…: pip install pymupdf
import fitz  # PyMuPDF
from PIL import Image

st.set_page_config(page_title="æ™ºèƒ½PDFå¤šæ¨¡æ€é—®ç­”ç³»ç»Ÿ", page_icon="ğŸ“š", layout="wide")

import shutil
import json
from langchain_community.embeddings import HuggingFaceEmbeddings
from src.parser.smart_parser import smart_extract, PaddleOCR
from src.rag.vector_storage import build_vector_db
from src.llm.rag_chain import get_answer_stream
from src.evaluation.evaluator import evaluate_response
from src.llm.graph_agent import extract_triplets_from_text, build_graph_config
from src.rag.reranker import get_reranker
from streamlit_agraph import agraph

# é¢„åŠ è½½æ¨¡å‹
@st.cache_resource
def load_models():
    print("â³ [ç³»ç»Ÿ] æ­£åœ¨åˆå§‹åŒ– Embedding æ¨¡å‹...")
    embeddings = HuggingFaceEmbeddings(model_name="shibing624/text2vec-base-chinese")
    try:
        get_reranker()
    except:
        pass
    return embeddings

with st.spinner("æ­£åœ¨å¯åŠ¨æ™ºèƒ½åˆ†æå¼•æ“..."):
    global_embed_model = load_models()

# ä¾§è¾¹æ é€»è¾‘
with st.sidebar:
    st.header("ğŸ“‚ æ–‡æ¡£ç®¡ç†")
    with st.expander("ğŸ› ï¸ ç³»ç»Ÿè¯Šæ–­"):
        st.write(f"**Python:** {sys.executable}")

    st.divider()
    DB_BASE_PATH = r"D:\workspace\finale_workspace\PDF_RAG_Project\data\vector_dbs"
    RAW_DATA_PATH = r"D:\workspace\finale_workspace\PDF_RAG_Project\data\raw"
    os.makedirs(DB_BASE_PATH, exist_ok=True)
    os.makedirs(RAW_DATA_PATH, exist_ok=True)
    
    uploaded_file = st.file_uploader("ä¸Šä¼  PDF æ–‡æ¡£", type="pdf")

    @st.cache_resource
    def init_ocr():
        return PaddleOCR(lang="ch", use_angle_cls=True)
    ocr_engine = init_ocr()
    
    if uploaded_file:
        # --- æ ¸å¿ƒä¿®æ”¹ï¼šå¼ºåˆ¶æ ‡å‡†åŒ–æ–‡ä»¶å ---
        # 1. æŠŠæ–‡ä»¶åé‡Œçš„ç©ºæ ¼å¼ºåˆ¶æ¢æˆä¸‹åˆ’çº¿ï¼Œé˜²æ­¢è·¯å¾„åŒ¹é…é”™è¯¯
        clean_filename = uploaded_file.name.replace(" ", "_")
        
        # 2. ç¡®å®š PDF å­˜å‚¨è·¯å¾„ (å­˜ä¸‹å»çš„å°±æ˜¯æ ‡å‡†åŒ–çš„åå­—)
        file_path = os.path.join(RAW_DATA_PATH, clean_filename)
        
        # 3. ç¡®å®šæ•°æ®åº“åç§° (å»æ‰ .pdf åç¼€)
        # è¿™æ · PDF æ–‡ä»¶å = "My_File.pdf"ï¼Œæ•°æ®åº“å = "My_File"ï¼Œå®Œå…¨å¯¹åº”
        db_name = clean_filename.replace(".pdf", "")
        target_db_path = os.path.join(DB_BASE_PATH, db_name)

        # ä¿å­˜æ–‡ä»¶
        with open(file_path, "wb") as f:
            f.write(uploaded_file.getbuffer())
        
        if st.button("ğŸš€ å¼€å§‹æ™ºèƒ½è§£æ"):
            with st.status("æ­£åœ¨å¤„ç†æ–‡æ¡£...", expanded=True) as status:
                st.write("ğŸ” OCR æ–‡æœ¬/å›¾è¡¨è¯†åˆ«...")
                pages_data = smart_extract(file_path, ocr_engine)
                st.write("ğŸ§  å»ºç«‹è¯­ä¹‰ç´¢å¼•...")
                # æ³¨æ„ï¼šè¿™é‡Œä¼ å…¥ clean_filenameï¼Œç¡®ä¿åç»­é€»è¾‘ä¸€è‡´
                build_vector_db(pages_data, clean_filename, embedding_model=global_embed_model)
                status.update(label="âœ… å…¥åº“å®Œæˆ", state="complete")
            st.rerun()

    st.divider()
    existing_dbs = [d for d in os.listdir(DB_BASE_PATH) if os.path.isdir(os.path.join(DB_BASE_PATH, d))]
    
    # å…¨å±€å˜é‡ï¼šå½“å‰é€‰ä¸­çš„çŸ¥è¯†åº“åç§°
    selected_db_name = None 
    
    if existing_dbs:
        selected_db_name = st.selectbox("é€‰æ‹©çŸ¥è¯†åº“ï¼š", existing_dbs)
        current_db_path = os.path.join(DB_BASE_PATH, selected_db_name)
        if st.button("ğŸ—‘ï¸ åˆ é™¤"):
            shutil.rmtree(current_db_path)
            st.rerun()
    else:
        st.warning("æš‚æ— çŸ¥è¯†åº“")
        current_db_path = None

# ä¸»ç•Œé¢
st.title("ğŸ¤– PDF æ™ºèƒ½é—®ç­”ç³»ç»Ÿ")
st.caption("ğŸš€ æ”¯æŒå¤šæ¨¡æ€è§£æ Â· æ··åˆæ£€ç´¢ Â· åŸæ–‡æˆªå›¾ Â· çŸ¥è¯†å›¾è°±")
st.divider()

if "messages" not in st.session_state: st.session_state.messages = []
if "latest_qa_pair" not in st.session_state: st.session_state.latest_qa_pair = None

# --- æ ¸å¿ƒï¼šæ¸²æŸ“å†å²æ¶ˆæ¯ (å« PDF æˆªå›¾) ---
for i, msg in enumerate(st.session_state.messages):
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])
        
        if msg["role"] == "assistant":
            # 1. æ¥æºæ–‡æ¡£ + PDF æˆªå›¾
            if "source_docs" in msg and msg["source_docs"]:
                with st.expander("ğŸ“– å‚è€ƒæ¥æº & åŸæ–‡æˆªå›¾"):
                    docs = msg["source_docs"]
                    # ä½¿ç”¨ Tabs åˆ‡æ¢ä¸åŒæ¥æº
                    tabs = st.tabs([f"ğŸ“„ P{d.metadata.get('source_page', '?')}" for d in docs[:3]])
                    
                    for idx, tab in enumerate(tabs):
                        with tab:
                            doc = docs[idx]
                            c1, c2 = st.columns([1, 1])
                            
                            # å·¦ä¾§ï¼šæ–‡å­—å†…å®¹
                            with c1:
                                st.caption("ğŸ” æå–æ–‡æœ¬")
                                st.info(f"{doc.page_content}...")
                            
                            # å³ä¾§ï¼šPDF æˆªå›¾ (ç»æ´»åŠŸèƒ½)
                            with c2:
                                try:
                                    if selected_db_name:
                                        # --- æ ¸å¿ƒä¿®æ”¹ï¼šç›´æ¥æ‹¼æ¥ï¼Œæ— éœ€çŒœæµ‹ ---
                                        # å› ä¸ºæˆ‘ä»¬åœ¨ä¸Šä¼ æ—¶å·²ç»å¼ºåˆ¶ç»Ÿä¸€äº†å‘½åè§„åˆ™ï¼š
                                        # æ•°æ®åº“å "My_File" -> å¯¹åº”çš„ PDF ä¸€å®šæ˜¯ "My_File.pdf"
                                        pdf_name = selected_db_name + ".pdf"
                                        pdf_file_path = os.path.join(RAW_DATA_PATH, pdf_name)
                                        
                                        if os.path.exists(pdf_file_path):
                                            # æ³¨æ„ï¼šsource_page æœ‰æ—¶å€™å¯èƒ½æ˜¯ stringï¼Œå®‰å…¨è½¬ int
                                            page_num = int(doc.metadata.get('source_page', 1)) - 1
                                            
                                            with fitz.open(pdf_file_path) as pdf:
                                                # å®‰å…¨æ£€æŸ¥é¡µç èŒƒå›´
                                                if 0 <= page_num < len(pdf):
                                                    page = pdf[page_num]
                                                    # ç¼©æ”¾ç³»æ•° 2 è¡¨ç¤º 2 å€æ¸…æ™°åº¦
                                                    pix = page.get_pixmap(matrix=fitz.Matrix(2, 2))
                                                    img = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)
                                                    st.image(img, caption=f"ğŸ“¸ åŸæ–‡ P{page_num+1} æˆªå›¾", use_column_width=True)
                                                else:
                                                    st.warning(f"é¡µç  {page_num+1} è¶…å‡ºæ–‡æ¡£èŒƒå›´")
                                        else:
                                            # å¦‚æœæ‰¾ä¸åˆ°ï¼Œæ‰“å°ä¸€ä¸‹è·¯å¾„æ–¹ä¾¿è°ƒè¯•
                                            st.warning(f"æœªæ‰¾åˆ°æºæ–‡ä»¶: {pdf_name}")
                                            st.caption(f"è¯·ç¡®è®¤ {RAW_DATA_PATH} ç›®å½•ä¸‹æ˜¯å¦å­˜åœ¨è¯¥æ–‡ä»¶")
                                except Exception as e:
                                    st.error(f"æˆªå›¾åŠ è½½å¤±è´¥: {e}")

# è¾“å…¥å¤„ç†
if prompt := st.chat_input("è¯·è¾“å…¥å…³äºæ–‡æ¡£çš„é—®é¢˜..."):
    if not current_db_path:
        st.error("è¯·å…ˆä¸Šä¼ æˆ–é€‰æ‹©ä¸€ä¸ªæ–‡æ¡£ï¼")
        st.stop()

    # ç”¨æˆ·æ¶ˆæ¯ä¸Šå±
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # åŠ©æ‰‹å›å¤
    with st.chat_message("assistant"):
        msg_placeholder = st.empty()
        full_response = ""
        
        responses, source_docs = get_answer_stream(
            prompt, 
            current_db_path, 
            st.session_state.messages,
            embedding_model=global_embed_model
        )
        
        for response in responses:
            if response.status_code == 200:
                chunk = response.output.choices[0].message.content
                full_response += chunk
                msg_placeholder.markdown(full_response + "â–Œ")
        
        msg_placeholder.markdown(full_response)

        # æ„å»ºä¸Šä¸‹æ–‡
        context_str = "\n\n".join([f"[P{d.metadata.get('source_page')}] {d.page_content}" for d in source_docs])
        
        # ç”Ÿæˆå›¾è°±
        current_graph = None
        with st.spinner("æ­£åœ¨åˆ†æå®ä½“å…³ç³»..."):
            triplets = extract_triplets_from_text(context_str)
            if triplets:
                nodes, edges, config = build_graph_config(triplets)
                current_graph = {"nodes": nodes, "edges": edges, "config": config}
            else:
                current_graph = "empty"

        # æ‰“åŒ…å­˜å…¥å†å²
        st.session_state.messages.append({
            "role": "assistant", 
            "content": full_response,
            "source_docs": source_docs,
            "graph_data": current_graph
        })

        # ä¿å­˜æœ€æ–°æ•°æ®ç”¨äºä¸‹æ–¹å±•ç¤º
        st.session_state.latest_qa_pair = {
            "query": prompt,
            "context": context_str,
            "response": full_response,
            "graph": current_graph
        }
        
        st.rerun()

# --- åº•éƒ¨åŠŸèƒ½åŒº (åªé’ˆå¯¹æœ€æ–°ä¸€æ¡) ---
if st.session_state.latest_qa_pair:
    latest_data = st.session_state.latest_qa_pair
    
    # 1. çŸ¥è¯†å›¾è°± (åªæ˜¾ç¤ºæœ€æ–°çš„ï¼Œé¿å… key æŠ¥é”™)
    graph = latest_data.get("graph")
    if graph and graph != "empty":
        st.divider()
        st.subheader("ğŸ•¸ï¸ å½“å‰æ€ç»´å›¾è°±")
        agraph(nodes=graph["nodes"], edges=graph["edges"], config=graph["config"])

    # 2. è´¨é‡è¯„ä¼°
    st.divider()
    with st.expander("ğŸ“Š è´¨é‡è¯„ä¼° (é’ˆå¯¹æœ€æ–°é—®ç­”)"):
        col1, col2 = st.columns([1, 4])
        with col1:
            if st.button("âœ¨ è¯„åˆ†"):
                with st.spinner("è¯„ä¼°ä¸­..."):
                    raw = evaluate_response(latest_data["query"], latest_data["context"], latest_data["response"])
                    try:
                        res = json.loads(raw.replace("```json", "").replace("```", "").strip())
                        st.info(f"å¿ å®åº¦: {res.get('faithfulness')}/10 | ç›¸å…³æ€§: {res.get('relevance')}/10")
                        st.caption(res.get('reason'))
                    except:
                        st.write(raw)